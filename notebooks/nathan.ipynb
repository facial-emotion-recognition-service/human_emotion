{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 07:35:03.050041: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-14 07:35:03.058242: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-14 07:35:03.204366: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-14 07:35:03.205416: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-14 07:35:04.246990: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from PIL import Image\n",
    "import tensorflow as tf"
   ]
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> 3413de12165d6143144b13067841754ec8c8e8c7
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "Build our X and y with all the data we need "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../raw_data/faces/' \n",
    "folders = [x[0] for x in os.walk(directory)][1:]  #ignore the first folder which is the root dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = {'anger': 0, \n",
    "            'contempt': 1, \n",
    "            'disgust': 2,\n",
    "            'fear': 3,\n",
    "            'happiness': 4,\n",
    "            'neutrality': 5,\n",
    "            'sadness': 6, \n",
    "            'surprise': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "data = []\n",
    "emotions_enum = []\n",
    "for folder in folders: \n",
    "    for filename in os.listdir(folder): \n",
    "        emotion = os.path.basename(folder) #get folder name \n",
    "        f = os.path.join(folder, filename)\n",
    "        data.append([f, filename, emotions[emotion]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=('path','file_name', 'emotion'))\n",
    "df = df.drop_duplicates(subset = ['file_name'], keep=False)\n",
    "files = list(df['path'])\n",
    "labels = list(df['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims = []\n",
    "\n",
    "for f in files:\n",
    "    if os.path.isfile(f):\n",
    "        im = Image.open(f)\n",
    "        im = np.expand_dims(np.array(im), axis=2)\n",
    "        ims.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(set(labels))\n",
    "y = to_categorical(labels, num_classes)\n",
    "X = np.array(ims)\n",
    "p = np.random.permutation(len(X))\n",
    "X, y = X[p], y[p]\n",
    "\n",
    "first_split = int(len(X) /6.)\n",
    "second_split = first_split + int(len(X) * 0.2)\n",
    "X_test, X_val, X_train = X[:first_split], X[first_split:second_split], X[second_split:]\n",
    "y_test, y_val, y_train = y[:first_split], y[first_split:second_split], y[second_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(851, 224, 224, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "\n",
    "def load_model():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(16, kernel_size=10, activation='relu', input_shape=(224, 224, 1)))\n",
    "    model.add(layers.Dropout(.35))\n",
    "    model.add(layers.MaxPooling2D(3))\n",
    "    \n",
    "    model.add(layers.Conv2D(32, kernel_size=8, activation=\"relu\"))\n",
    "    model.add(layers.Dropout(.35))\n",
    "    model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "\n",
    "    model.add(layers.Conv2D(32, kernel_size=4, activation=\"relu\"))\n",
    "    #model.add(layers.Dropout(.05))\n",
    "    model.add(layers.MaxPooling2D(2))\n",
    "    \n",
    "    model.add(layers.Conv2D(32, kernel_size=4, activation=\"relu\"))\n",
    "    #model.add(layers.Dropout(.05))\n",
    "    model.add(layers.MaxPooling2D(3))\n",
    "    \n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(100, activation='relu'))\n",
    "    model.add(layers.Dense(8, activation='softmax'))\n",
    "    \n",
    "    opt = optimizers.Adam(learning_rate=1e-4)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_20 (Conv2D)          (None, 215, 215, 16)      1616      \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 215, 215, 16)      0         \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 71, 71, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 64, 64, 32)        32800     \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 64, 64, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 29, 29, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 14, 14, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 11, 11, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 3, 3, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 288)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 100)               28900     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 8)                 808       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 96,956\n",
      "Trainable params: 96,956\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_ = load_model()\n",
    "model_.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "203/203 [==============================] - 27s 130ms/step - loss: 2.6251 - accuracy: 0.1996 - val_loss: 1.9700 - val_accuracy: 0.2674\n",
      "Epoch 2/100\n",
      "203/203 [==============================] - 30s 147ms/step - loss: 1.9659 - accuracy: 0.2670 - val_loss: 1.9349 - val_accuracy: 0.3154\n",
      "Epoch 3/100\n",
      "203/203 [==============================] - 27s 135ms/step - loss: 1.9050 - accuracy: 0.2948 - val_loss: 1.9347 - val_accuracy: 0.3095\n",
      "Epoch 4/100\n",
      "203/203 [==============================] - 35s 172ms/step - loss: 1.8530 - accuracy: 0.3155 - val_loss: 1.8923 - val_accuracy: 0.3232\n",
      "Epoch 5/100\n",
      "203/203 [==============================] - 34s 169ms/step - loss: 1.8145 - accuracy: 0.3344 - val_loss: 1.8935 - val_accuracy: 0.3448\n",
      "Epoch 6/100\n",
      "203/203 [==============================] - 35s 173ms/step - loss: 1.7607 - accuracy: 0.3538 - val_loss: 1.8581 - val_accuracy: 0.3555\n",
      "Epoch 7/100\n",
      "203/203 [==============================] - 34s 170ms/step - loss: 1.7292 - accuracy: 0.3674 - val_loss: 1.8204 - val_accuracy: 0.3624\n",
      "Epoch 8/100\n",
      "203/203 [==============================] - 34s 170ms/step - loss: 1.7017 - accuracy: 0.3798 - val_loss: 1.7951 - val_accuracy: 0.3692\n",
      "Epoch 9/100\n",
      "203/203 [==============================] - 34s 167ms/step - loss: 1.6399 - accuracy: 0.4061 - val_loss: 1.7692 - val_accuracy: 0.3575\n",
      "Epoch 10/100\n",
      "203/203 [==============================] - 34s 166ms/step - loss: 1.5892 - accuracy: 0.4302 - val_loss: 1.7929 - val_accuracy: 0.3643\n",
      "Epoch 11/100\n",
      "203/203 [==============================] - 34s 168ms/step - loss: 1.5608 - accuracy: 0.4261 - val_loss: 1.7301 - val_accuracy: 0.3967\n",
      "Epoch 12/100\n",
      "203/203 [==============================] - 34s 168ms/step - loss: 1.4963 - accuracy: 0.4512 - val_loss: 1.7148 - val_accuracy: 0.4123\n",
      "Epoch 13/100\n",
      "203/203 [==============================] - 34s 167ms/step - loss: 1.4498 - accuracy: 0.4762 - val_loss: 1.7187 - val_accuracy: 0.4045\n",
      "Epoch 14/100\n",
      "203/203 [==============================] - 34s 167ms/step - loss: 1.4209 - accuracy: 0.4941 - val_loss: 1.6978 - val_accuracy: 0.3888\n",
      "Epoch 15/100\n",
      "203/203 [==============================] - 34s 167ms/step - loss: 1.3698 - accuracy: 0.5049 - val_loss: 1.7507 - val_accuracy: 0.3820\n",
      "Epoch 16/100\n",
      "203/203 [==============================] - 34s 170ms/step - loss: 1.3461 - accuracy: 0.5133 - val_loss: 1.7135 - val_accuracy: 0.3928\n",
      "Epoch 17/100\n",
      "203/203 [==============================] - 34s 167ms/step - loss: 1.2839 - accuracy: 0.5380 - val_loss: 1.6693 - val_accuracy: 0.3976\n",
      "Epoch 18/100\n",
      "203/203 [==============================] - 34s 169ms/step - loss: 1.2564 - accuracy: 0.5522 - val_loss: 1.6998 - val_accuracy: 0.3947\n",
      "Epoch 19/100\n",
      "203/203 [==============================] - 34s 167ms/step - loss: 1.2176 - accuracy: 0.5711 - val_loss: 1.6550 - val_accuracy: 0.4163\n",
      "Epoch 20/100\n",
      "203/203 [==============================] - 34s 168ms/step - loss: 1.1834 - accuracy: 0.5698 - val_loss: 1.6674 - val_accuracy: 0.3976\n",
      "Epoch 21/100\n",
      "203/203 [==============================] - 34s 168ms/step - loss: 1.1187 - accuracy: 0.6011 - val_loss: 1.6749 - val_accuracy: 0.3928\n",
      "Epoch 22/100\n",
      "203/203 [==============================] - 34s 168ms/step - loss: 1.0824 - accuracy: 0.6208 - val_loss: 1.6682 - val_accuracy: 0.4133\n",
      "Epoch 23/100\n",
      "203/203 [==============================] - 34s 167ms/step - loss: 1.0429 - accuracy: 0.6156 - val_loss: 1.6667 - val_accuracy: 0.4163\n",
      "Epoch 24/100\n",
      "203/203 [==============================] - 36s 179ms/step - loss: 0.9953 - accuracy: 0.6434 - val_loss: 1.6780 - val_accuracy: 0.4006\n",
      "Epoch 25/100\n",
      "203/203 [==============================] - 37s 184ms/step - loss: 0.9728 - accuracy: 0.6489 - val_loss: 1.6756 - val_accuracy: 0.4035\n",
      "Epoch 26/100\n",
      "203/203 [==============================] - 35s 172ms/step - loss: 0.9236 - accuracy: 0.6740 - val_loss: 1.6504 - val_accuracy: 0.4114\n",
      "Epoch 27/100\n",
      "203/203 [==============================] - 34s 166ms/step - loss: 0.8924 - accuracy: 0.6857 - val_loss: 1.6609 - val_accuracy: 0.4182\n",
      "Epoch 28/100\n",
      "203/203 [==============================] - 34s 166ms/step - loss: 0.8648 - accuracy: 0.6934 - val_loss: 1.6821 - val_accuracy: 0.4025\n",
      "Epoch 29/100\n",
      "203/203 [==============================] - 34s 168ms/step - loss: 0.8093 - accuracy: 0.7191 - val_loss: 1.6796 - val_accuracy: 0.4163\n",
      "Epoch 30/100\n",
      "203/203 [==============================] - 34s 167ms/step - loss: 0.7771 - accuracy: 0.7268 - val_loss: 1.6927 - val_accuracy: 0.4074\n",
      "Epoch 31/100\n",
      "203/203 [==============================] - 34s 169ms/step - loss: 0.7495 - accuracy: 0.7367 - val_loss: 1.7000 - val_accuracy: 0.4290\n",
      "Epoch 32/100\n",
      "203/203 [==============================] - 34s 168ms/step - loss: 0.7033 - accuracy: 0.7503 - val_loss: 1.7146 - val_accuracy: 0.4192\n",
      "Epoch 33/100\n",
      "203/203 [==============================] - 34s 167ms/step - loss: 0.6997 - accuracy: 0.7596 - val_loss: 1.7116 - val_accuracy: 0.4133\n",
      "Epoch 34/100\n",
      "203/203 [==============================] - 34s 168ms/step - loss: 0.6515 - accuracy: 0.7710 - val_loss: 1.7654 - val_accuracy: 0.4084\n",
      "Epoch 35/100\n",
      "203/203 [==============================] - 34s 169ms/step - loss: 0.6206 - accuracy: 0.7834 - val_loss: 1.7776 - val_accuracy: 0.3967\n",
      "Epoch 36/100\n",
      "203/203 [==============================] - 35s 170ms/step - loss: 0.5858 - accuracy: 0.7982 - val_loss: 1.7754 - val_accuracy: 0.3888\n",
      "Epoch 37/100\n",
      "203/203 [==============================] - 34s 168ms/step - loss: 0.5760 - accuracy: 0.7988 - val_loss: 1.8509 - val_accuracy: 0.3986\n",
      "Epoch 38/100\n",
      "203/203 [==============================] - 34s 166ms/step - loss: 0.5525 - accuracy: 0.8032 - val_loss: 1.7982 - val_accuracy: 0.4192\n",
      "Epoch 39/100\n",
      "203/203 [==============================] - 34s 167ms/step - loss: 0.5090 - accuracy: 0.8208 - val_loss: 1.7743 - val_accuracy: 0.4025\n",
      "Epoch 40/100\n",
      "203/203 [==============================] - 34s 166ms/step - loss: 0.4965 - accuracy: 0.8269 - val_loss: 1.8112 - val_accuracy: 0.4202\n",
      "Epoch 41/100\n",
      "202/203 [============================>.] - ETA: 0s - loss: 0.4619 - accuracy: 0.8369Restoring model weights from the end of the best epoch: 31.\n",
      "203/203 [==============================] - 34s 166ms/step - loss: 0.4627 - accuracy: 0.8368 - val_loss: 1.8039 - val_accuracy: 0.4202\n",
      "Epoch 41: early stopping\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor = 'val_accuracy', \n",
    "                   mode = 'max', \n",
    "                   patience = 10, \n",
    "                   verbose = 1, \n",
    "                   restore_best_weights = True)\n",
    "\n",
    "history = model_.fit(X_train, y_train,\n",
    "                             validation_data = (X_val, y_val),\n",
    "                             batch_size = 16, \n",
    "                             epochs = 100, \n",
    "                             callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 2s 77ms/step - loss: 2.4845 - accuracy: 0.4230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.4845263957977295, 0.4230317175388336]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add drop out layers\n",
    "## data augmentation \n",
    "\n",
    "## isolate face from image \n",
    "## new slack channel\n",
    "\n",
    "## what is required to run the model \n",
    "## short guide to use model \n",
    "## set up on google colab? who wants to do that?\n",
    "\n",
    "## 5/9 9 AM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
=======
    "Test"
   ]
>>>>>>> 3413de12165d6143144b13067841754ec8c8e8c7
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
